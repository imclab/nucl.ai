- title: "Multi-Kinect Motion Tracking and Interactive Installations"
  description: >
    <p>What goes into creating a multi-user multi-Kinect interactive installation to convey a somewhat abstract message, other than blood, sweat, and a lot of development time?</p>
    <p>I’ll discuss the process, our use of both open-source and off-the-shelf AI libraries, as well as when we roll our own. I’ll go over the challenges of building them, with a distributed team, with fuzzy design requirements to convey even fuzzier concepts, and against fixed and very tight deadlines.</p>
  speakers:
    - Ricardo J. Méndez
  room: masterclass
  time:
    start: "12:15"
    finish: "13:00"

- title: "Top Secret Virtual Reality (To Be Confirmed)"
  description: >
    .
  speakers:
  room: amphitheatre
  time:
    start: "14:00"
    finish: "14:45"

- title: "Living-Room Augmented Reality and Project Trains"
  description: >
    <p>As goggle-based AR slowly matures, there's a window of opportunity for projector-based AR experiences.  It's also a great way to learn about the technology and the impacts on design required to pull off augmented reality in practice &mdash; with a setup that works reliably now already!</p>
    <p>This short tutorial about <a href="http://project-trains.tumblr.com/">Project Trains</a> will show some of the biggest lessons learned from building an interactive living room experience from two kids, from the computer vision aspect to the crafting (litterally) of a projector-based experience with augmented toy tracks.</p>
  speakers:
    - Alex J. Champandard
  room: masterclass
  time:
    start: "16:15"
    finish: "16:45"

- title: Object Recognition with Neural Networks (Workshop)
  description: >
    <p>This workshop is a tutorial for recognizing images of objects with modern neural networks.  You'll use open-source libraries and get up-to-speed with Deep Learning, understanding how to apply deep neural networks in practice as both classifiers (to predict labels from input features) or regressors (to predict an output based on inputs).</p>
    <p>This hands-on tutarial will show you how to get up and running on your own laptop, how to train neural networks and adjust their parameters, and how to "augment" input datasets for better results.  You'll see how this works in code, at your own pace, and with help and advice from the authors of a popular open-source library.</p>  
  room: laboratories
  speakers:
    - Spyridon Samothrakis
  time:
    start: "10:00"
    finish: "12:15"

- title: AR/VR Demo Time in the Conference Lobby!
  description: >
    Throw fireballs in a magical fairyland brought into life by Leap Motion Hand Tracking and the Oculus Rift (DK2).  Get your hands on the Rift, Hydra, Leap Motion and other devices and experience what VR is about! 
  room: laboratories
  speakers:
    - Richard Kogelnig
  time:
    start: "14:45"
    finish: "15:45"
